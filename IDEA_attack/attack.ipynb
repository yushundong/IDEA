{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stealing_link.attack_eraser import StealingAttack\n",
    "from stealing_link.partial_graph_generation import PartialGraphGeneration \n",
    "import config\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Planetoid, Coauthor\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "file_path = '/IDEA/attack_materials/IDEA_cora_edge_0.05_SGC.pth'\n",
    "model = torch.load(file_path)\n",
    "\n",
    "args = {}\n",
    "args['partial_graph_path'] = 'data/partial_graph_with_id/'\n",
    "args['attack_partial_graph_ratio'] =0.5\n",
    "args['attack_operator'] = 'concate_all'\n",
    "args['attack_metric_type'] = 'kl_divergence'\n",
    "args['dataset_name'] = 'cora'\n",
    "args['ratio_unlearned'] = 0.05\n",
    "args['exp'] = 'edge'\n",
    "\n",
    "if args['dataset_name'] in [\"cora\", \"pubmed\", \"citeseer\"]:\n",
    "            dataset = Planetoid(\n",
    "                'raw_data', args['dataset_name'], transform=T.NormalizeFeatures()\n",
    "            )\n",
    "            labels = np.unique(dataset.data.y.numpy())\n",
    "            data = dataset[0]\n",
    "elif args['dataset_name'] in [\"Coauthor_CS\", \"Coauthor_Phys\"]:\n",
    "    if args['dataset_name'] == \"Coauthor_Phys\":\n",
    "        dataset = Coauthor(\n",
    "            'raw_data', name=\"Physics\",\n",
    "        )\n",
    "        data = dataset[0]\n",
    "        feature = data.x\n",
    "        pca = PCA(n_components=500)\n",
    "        reduced_feature = pca.fit_transform(feature.cpu().detach().numpy())\n",
    "        data.x = torch.from_numpy(reduced_feature)\n",
    "    else:\n",
    "        dataset = Coauthor(\n",
    "            config.RAW_DATA_PATH, name=\"CS\",\n",
    "        )\n",
    "        data = dataset[0]\n",
    "else:\n",
    "    raise Exception(\"unsupported dataset\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PartialGraphGeneration(args, data, model['removed_edges'], model['predicted_prob'])\n",
    "# StealingAttack(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['removed_edges', 'unlearned_feature_pre', 'predicted_prob', 'train_indices', 'test_indices'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "& xx.xx $\\pm$ x.x     & 50.11 $\\pm$ 0.9        \\\\\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# pd.read_csv('result/attack_results.csv')\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('result/attack_results.csv')\n",
    "\n",
    "# Calculate the mean and standard deviation for accuracy\n",
    "\n",
    "mean_accuracy = df['Test AUC'].mean()*100\n",
    "std_accuracy = df['Test AUC'].std()*100\n",
    "print(f'& xx.xx $\\pm$ x.x     & {mean_accuracy:.2f} $\\pm$ {std_accuracy:.1f}        \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Node attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from mia.MLG_TSTF import MIA\n",
    "import config\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Planetoid, Coauthor\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "file_path = '../IDEA/attack_materials/IDEA_cora_node_0.05_SGC.pth'\n",
    "model = torch.load(file_path)\n",
    "\n",
    "args = {}\n",
    "args['dataset_name'] = 'cora'\n",
    "args['ratio_unlearned'] = 0.05\n",
    "args['exp'] = 'node'\n",
    "\n",
    "if args['dataset_name'] in [\"cora\", \"pubmed\", \"citeseer\"]:\n",
    "            dataset = Planetoid(\n",
    "                'raw_data', args['dataset_name'], transform=T.NormalizeFeatures()\n",
    "            )\n",
    "            labels = np.unique(dataset.data.y.numpy())\n",
    "            data = dataset[0]\n",
    "elif args['dataset_name'] in [\"Coauthor_CS\", \"Coauthor_Phys\"]:\n",
    "    if args['dataset_name'] == \"Coauthor_Phys\":\n",
    "        dataset = Coauthor(\n",
    "            'raw_data', name=\"Physics\",\n",
    "        )\n",
    "        data = dataset[0]\n",
    "        feature = data.x\n",
    "        pca = PCA(n_components=500)\n",
    "        reduced_feature = pca.fit_transform(feature.cpu().detach().numpy())\n",
    "        data.x = torch.from_numpy(reduced_feature)\n",
    "    else:\n",
    "        dataset = Coauthor(\n",
    "            config.RAW_DATA_PATH, name=\"CS\",\n",
    "        )\n",
    "        data = dataset[0]\n",
    "else:\n",
    "    raise Exception(\"unsupported dataset\")\n",
    "\n",
    "train_indices = model['train_indices'].nonzero().view(-1)\n",
    "test_indices = model['test_indices'].nonzero().view(-1)\n",
    "MIA(args, model['predicted_prob'], model['removed_nodes'], train_indices, test_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteior Residue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stealing_link.attack_eraser import StealingAttack\n",
    "from stealing_link.partial_graph_generation import PartialGraphGeneration \n",
    "import config\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import Planetoid, Coauthor\n",
    "import torch_geometric.transforms as T\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F\n",
    "\n",
    "file_path = '../IDEA/attack_materials/IDEA_cora_partial_feature_0.05_SGC.pth'\n",
    "model = torch.load(file_path)\n",
    "\n",
    "# Convert data.y to one-hot encoding\n",
    "one_hot_y = F.one_hot(data.y, num_classes=dataset.num_classes).cpu()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.260506272315979\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your predicted probabilities and target labels\n",
    "predicted_probs = (model['unlearned_feature_pre'])[model['unlearned_feature_node_idx']]  # Example predicted probabilities\n",
    "target_labels = data.y[model['unlearned_feature_node_idx']]  # Example target labels\n",
    "\n",
    "# Calculate the cross-entropy loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(predicted_probs, target_labels)\n",
    "\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2976230382919312\n"
     ]
    }
   ],
   "source": [
    "# Define your predicted probabilities and target labels\n",
    "predicted_probs = (model['predicted_prob'].cpu())[model['unlearned_feature_node_idx']]  # Example predicted probabilities\n",
    "target_labels = data.y[model['unlearned_feature_node_idx']]  # Example target labels\n",
    "\n",
    "# Calculate the cross-entropy loss\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss = loss_fn(predicted_probs, target_labels)\n",
    "\n",
    "print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ceu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
